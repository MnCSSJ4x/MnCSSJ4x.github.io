<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Monjoy Naryaan Choudhury</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Monjoy Narayan Choudhury
                </p>
                <p>
                    Hi! I'm a Master's student at IIIT Bangalore. My research interest involves "Undestanding Visual Contributions to Vision-Language Models" and Adverserial Attacks and their defenses for current VLMs in production. I am also an upcoming SWE at Google India!
                </p>
                <p>
                  Previously at Google, India, as an intern, I developed a sampling mechanism for query-set reduction in the real-time feature monitoring pipeline for Google Search. My approach, using metric and graph clustering with greedy heuristics, improved coverage by 57% while reducing the query set by 50%, optimizing pre-production testing.
                  
                </p>
                <p>
                  At Bosch Research, I worked on applying Vision-Language Models (VLMs) for autonomous driving, focusing on in-context learning, model optimization, and evaluation. I also developed an LLM-based domain-specific metric to assess caption quality for autonomous driving scene descriptions.
                </p>
                <p>    
                  As part of my masters project, I am working at the ETH Language Reasoning and Education Lab on evaluating Large Vision-Language Models (VLMs) for visual reasoning tasks using simple mathematical games. My focus is on assessing their ability to combine recognition along with reasoning capabilities that are transferred from LLMs and I intend to answer the overall question - "Are VLMs reasoning blindly?"
                </p>
                <p style="text-align:center">
                  <a href="mailto:monjoychoudhury29@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="files/Monjoy_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=oz9jBEgAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/NarayanMonjoy">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/MnCSSJ4x/">Github</a> &nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:50%;max-width:50%">
                <a href="images/my-photo.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/my-photo.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
            <tr>
              <td width="13.8%" valign="top" align="center">
                <img src="images/lre-lab.png" alt="sym" width="60%"></a>
                <p style="line-height:1.3;"><a href="https://lre.inf.ethz.ch/">Language, Reasoning, Education Lab @ ETH ZÃ¼rich</a><br>Master's Project Student<br>Aug. 24 - Jan. 25</p>
              </td>
                <td width="13.8%" valign="top" align="center">
                  <img src="images/bosch-research.jpeg" alt="sym" width="60%"></a>
                  <p style="line-height:1.3;"><a href="https://www.bosch.com/research/">Bosch Research</a><br>Research Intern<br>Aug. 24 - Jan. 25</p>
              </td>
  
                <td width="13.8%" valign="top" align="center">
                  <img src="images/google.png" alt="sym" width="60%"></a>
                  <p style="line-height:1.3;"><a href="https://www.google.com/about/careers/applications/">Google</a><br>SWE Intern<br>May. 24 - Jul. 24</p>
                  </td>
        
                <td width="16.6%" valign="top" align="center">
                <img src="images/iiitb_logo.png" alt="sym" width="55%"></a>
                <p style="line-height:1.3;"><a href="https://iiitb.ac.in/">IIIT Bangalore</a><br>
                  B.Tech. Computer Science <br>
                  M.Tech. AI/ML<br>
                  Nov. 2020  - Jul. 25</p>
                </td>
            </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <span>
              <h2>Research Work </h2> (*denotes equal contribution) 
              </span>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
        
            <!-- CASE: Curricular Data Pre-training for Building Generative and Discriminative Assistive Psychology Expert Models -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/Case-image.png' width="200" alt="CASE Project Static Image">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://aclanthology.org/2024.findings-emnlp.925.pdf">
                  <span class="papertitle">CASE: Curricular Data Pre-training for Building Generative and Discriminative Assistive Psychology Expert Models</span>
                </a>
                <br>
                Harne, S.*, <strong>Choudhury, M.N.</strong>*, Rao, M., Srikanth, T.K., Mehrotra, S., Vashisht, A., Basu, A., Sodhi, M.
                <br>
                <em>Findings of the Association for Computational Linguistics: EMNLP</em>, 2024
                <br>
                <a href="https://aclanthology.org/2024.findings-emnlp.925.pdf">paper</a>
                <p></p>
                <p>
                  This work presents a pre-training method for both discriminative and generative models in assistive psychology. By leveraging curricular texts from mental health institutes for pre-training, we introduce CASE-BERT, a discriminative model that identifies potential mental health disorders from forum posts. CASE-BERT achieves state-of-the-art performance, with an F1 score of 0.91 for Depression and 0.88 for Anxiety, enabling more accurate and efficient preliminary screenings. This approach enhances mental health assessments by automating early detection while addressing data privacy and scarcity challenges.
                </p>
              </td>
            </tr>
        
            <!-- RID-TWIN: An End-to-End Pipeline for Automatic Face De-Identification in Videos -->
            <tr onmouseout="rid_stop()" onmouseover="rid_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='rid_image'>
                    <video width="200" muted autoplay loop>
                      <source src="images/rid_twin_demo.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src='images/rid-image.png' width="200" alt="RID-TWIN Project Static Image">
                </div>
                <script type="text/javascript">
                  function rid_start() {
                    document.getElementById('rid_image').style.opacity = "1";
                  }
        
                  function rid_stop() {
                    document.getElementById('rid_image').style.opacity = "0";
                  }
                  rid_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2403.10058">
                  <span class="papertitle">RID-TWIN: An End-to-End Pipeline for Automatic Face De-Identification in Videos</span>
                </a>
                <br>
                Mukherjee, A., <strong>Choudhury, M.N.</strong>, Jayagopi, D.B.
                <br>
                <em>arXiv preprint</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2403.10058">paper</a>
                <p></p>
                <p>
                  Face de-identification in videos is a critical task for privacy preservation in computer vision. This work introduces RID-TWIN, a novel pipeline that leverages state-of-the-art generative models to decouple identity from motion, enabling automatic face de-identification in videos. The approach addresses challenges such as realism, temporal coherence, and preservation of non-identifiable features. Evaluations on the VoxCeleb2 dataset and a custom dataset demonstrate the effectiveness of RID-TWIN in producing de-identified videos while maintaining visual quality and consistency.
                </p>
              </td>
            </tr>

      <!-- A Systematic Review of Online Learning Platforms for Computer Science Courses -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/edunine.png" alt="Online Learning Platforms Review" width="200" style="border-style: none">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.researchgate.net/publication/370200160_A_Systematic_Review_of_Online_Learning_Platforms_for_Computer_Science_Courses">
            <span class="papertitle">A Systematic Review of Online Learning Platforms for Computer Science Courses</span>
          </a>
          <br>
          Praseeda, <strong>Choudhury, M.N.</strong>, Chadha, B.S., Srinivasa, S.
          <br>
          <em>IEEE World Engineering Education Conference (EDUNINE)</em>, 2023
          <br>
          <a href="https://www.researchgate.net/publication/370200160_A_Systematic_Review_of_Online_Learning_Platforms_for_Computer_Science_Courses">paper</a>
          <p></p>
          <p>
            This systematic review examines various online learning platforms utilized for computer science education. The study aims to understand how technology has influenced learning systems through the integration of Information and Communication Technology (ICT) in online education. By analyzing existing platforms, the review identifies trends, challenges, and best practices, providing insights into the effectiveness of online learning tools in delivering computer science courses.
          </p>
        </td>
      </tr>
        
          </tbody>
        </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                Source code from <a href="https://github.com/jonbarron/jonbarron_website"> Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
